import json
from datetime import datetime

import numpy as np
import torch
import torch.nn as nn
from matplotlib import pyplot as plt
from sklearn.metrics import accuracy_score as acc, precision_score as pr, recall_score as rc, f1_score as f1
from torch.optim import Adam

from create_data.data_graph_loader import create_data_set_from_json


class BiLstmV2(nn.Module):
    def __init__(self, input_dim, hidden_dim, dropout_p=0.5):
        super(BiLstmV2, self).__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.layer_dropout = nn.Sequential(
            nn.Linear(in_features=self.input_dim, out_features=self.hidden_dim, bias=True),
            nn.ReLU()
        )
        self.layer_bi_lstm = nn.LSTM(self.hidden_dim, hidden_dim, bidirectional=True)
        self.dropout = nn.Dropout(dropout_p)
        self.layer_classification = nn.Sequential(
            nn.Linear(in_features=2 * self.hidden_dim, out_features=2),
            nn.ReLU(),
            nn.LogSoftmax(dim=-1)
        )

    def forward(self, example_batch, targets=None):
        layer_dropout = self.layer_dropout(example_batch)
        lstm_out, _ = self.layer_bi_lstm(layer_dropout.view(len(example_batch), 1, -1))
        lstm_out = lstm_out.view(len(example_batch), -1)
        lstm_out = self.dropout(lstm_out)
        layer_classification = self.layer_classification(lstm_out)

        props = torch.softmax(layer_classification, dim=1)
        batch_loss = None
        if targets is not None:
            loss_function = nn.CrossEntropyLoss()
            batch_loss = loss_function(layer_classification, targets)

        return props, batch_loss, layer_classification


if __name__ == '__main__':
    file_train = "../data_split/data_input60-10/train.json"
    file_valid = "../data_split/data_input60-10/valid.json"
    file_test = "../data_split/data_input60-10/test.json"
    file_results = "../data_split/data_input60-10/results_bilstm_v2.json"

    file_train_2 = "D:\\KHOA LUAN TOT NGHIEP\\folder_data\\after_ggnn\\devign\\v1\\train_GGNNinput_graph.json"
    file_valid_2 = "D:\\KHOA LUAN TOT NGHIEP\\folder_data\\after_ggnn\\devign\\v1\\valid_GGNNinput_graph.json"
    file_test_2 = "D:\\KHOA LUAN TOT NGHIEP\\folder_data\\after_ggnn\\devign\\v1\\test_GGNNinput_graph.json"
    # file_results = "../result"

    dataset = create_data_set_from_json(file_train, file_valid, file_test)
    dataset.init_dataset_loader()
    train_features, train_targets = dataset.convert_data_to_tensor(dataset.train_entries,
                                                                   list(range(len(dataset.train_entries))))

    dataset_for_test = create_data_set_from_json(file_train_2, file_valid_2, file_test_2)
    test_features, test_targets = dataset.convert_data_to_tensor(dataset_for_test.test_entries,
                                                                 list(range(len(dataset.train_entries))))
    accuracy_score_train = []
    accuracy_score_test = []

    lstm_model = BiLstmV2(input_dim=dataset.hdim, hidden_dim=2 * dataset.hdim)
    print(lstm_model)
    optimizer = Adam(lstm_model.parameters())

    for epoch in range(50):
        lstm_model.zero_grad()
        optimizer.zero_grad()
        prediction_prob, representation, batch_loss = lstm_model(
            example_batch=train_features,
            targets=train_targets)
        repr = representation.detach().cpu().numpy()
        prediction_classes = np.argmax(prediction_prob.detach().cpu().numpy(), axis=-1)
        acc_train = acc(train_targets, prediction_classes)
        accuracy_score_train.append(acc_train)

        if epoch % 1 == 0:
            prediction_prob, representation, batch_loss = lstm_model(
                example_batch=test_features,
                targets=test_targets)
            repr = representation.detach().cpu().numpy()
            prediction_classes = np.argmax(prediction_prob.detach().cpu().numpy(), axis=-1)

            print('=' * 100)
            acc_test = acc(test_targets, prediction_classes)
            pr_test = pr(test_targets, prediction_classes)
            rc_test = rc(test_targets, prediction_classes)
            f1_test = f1(test_targets, prediction_classes)
            accuracy_score_test.append(acc_test)
            print(
                "Test  %3d, Accuracy: %5.2f, Precision: %5.2f, Recall: %5.2f, F1: %5.2f" % (
                    epoch,
                    acc_test, pr_test,
                    rc_test, f1_test
                )
            )
            print('=' * 100)

            with open(file_results, 'w') as f:
                value = {
                    "date": str(datetime.now()),
                    "num_epoch": 50,
                    "Accuracy": acc_test,
                    "Precision": pr_test,
                    "Recall": rc_test,
                    "F1": f1_test
                }
                json.dump(value, f)
                f.close()

        batch_loss.sum().backward()
        optimizer.step()
    plt.plot(accuracy_score_train, label='train')
    plt.plot(accuracy_score_test, label='test')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Biểu đồ so sánh độ chính xác qua các epoch')
    plt.legend()
    plt.show()
