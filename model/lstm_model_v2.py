import json
from datetime import datetime

import numpy as np
import torch.nn as nn
import torch
from matplotlib import pyplot as plt
from torch.optim import Adam

from create_data.data_graph_loader import create_data_set_from_json
from model import train_model
from sklearn.metrics import accuracy_score as acc, precision_score as pr, recall_score as rc, f1_score as f1
from sklearn.metrics import precision_score


class LstmModelV2(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim=2, dropout_rate=0.7):
        super(LstmModelV2, self).__init__()
        self.hidden_dim = hidden_dim
        self.lstm = nn.LSTM(input_dim, hidden_dim)
        self.dropout = nn.Dropout(dropout_rate)

        self.classifier = nn.Sequential(
            nn.Linear(in_features=self.hidden_dim, out_features=2),
            nn.LogSoftmax(dim=-1)
        )

    def forward(self, example_batch, targets=None):
        lstm, _ = self.lstm(example_batch.view(len(example_batch), 1, -1))
        lstm = self.dropout(lstm)
        lstm = lstm.view(len(example_batch), -1)
        y_a = self.classifier(lstm)

        probs = torch.softmax(y_a, dim=1)

        batch_loss = None
        if targets is not None:
            loss_function = nn.CrossEntropyLoss()
            batch_loss = loss_function(y_a, targets)

        return probs, y_a, batch_loss

    def extract_feature(self, x):
        out = self.lstm(x)
        return out


if __name__ == '__main__':
    file_train = "../data_split/data_input60-10/train.json"
    file_valid = "../data_split/data_input60-10/valid.json"
    file_test = "../data_split/data_input60-10/test.json"
    file_results = "../data_split/data_input60-10/results_lstm_v2.json"

    file_train_2 = "D:\\KHOA LUAN TOT NGHIEP\\folder_data\\after_ggnn\\devign\\v1\\train_GGNNinput_graph.json"
    file_valid_2 = "D:\\KHOA LUAN TOT NGHIEP\\folder_data\\after_ggnn\\devign\\v1\\valid_GGNNinput_graph.json"
    file_test_2 = "D:\\KHOA LUAN TOT NGHIEP\\folder_data\\after_ggnn\\devign\\v1\\test_GGNNinput_graph.json"
    # file_results = "../result"

    dataset = create_data_set_from_json(file_train, file_valid, file_test)
    dataset.init_dataset_loader()
    train_features, train_targets = dataset.convert_data_to_tensor(dataset.train_entries,
                                                                   list(range(len(dataset.train_entries))))

    # dataset_for_test = create_data_set_from_json(file_train_2, file_valid_2, file_test_2)
    # test_features, test_targets = dataset.convert_data_to_tensor(dataset_for_test.test_entries,
    #                                                              list(range(len(dataset.train_entries))))

    test_features, test_targets = dataset.convert_data_to_tensor(dataset.test_entries,
                                                                 list(range(len(dataset.test_entries))))

    accuracy_score_train = []
    accuracy_score_test = []

    lstm_model = LstmModelV2(input_dim=dataset.hdim, hidden_dim=2 * dataset.hdim)
    print(lstm_model)
    optimizer = Adam(lstm_model.parameters())

    for epoch in range(50):
        lstm_model.zero_grad()
        optimizer.zero_grad()
        prediction_prob, representation, batch_loss = lstm_model(
            example_batch=train_features,
            targets=train_targets)
        repr = representation.detach().cpu().numpy()
        prediction_classes = np.argmax(prediction_prob.detach().cpu().numpy(), axis=-1)
        acc_train = acc(train_targets, prediction_classes)
        accuracy_score_train.append(acc_train)

        if epoch % 1 == 0:
            prediction_prob, representation, batch_loss = lstm_model(
                example_batch=test_features,
                targets=test_targets)
            repr = representation.detach().cpu().numpy()
            prediction_classes = np.argmax(prediction_prob.detach().cpu().numpy(), axis=-1)

            print('=' * 100)
            acc_test = acc(test_targets, prediction_classes)
            pr_test = pr(test_targets, prediction_classes)
            rc_test = rc(test_targets, prediction_classes)
            f1_test = f1(test_targets, prediction_classes)
            accuracy_score_test.append(acc_test)
            print(
                "Test  %3d, Loss: %10.4f, Accuracy: %5.2f, Precision: %5.2f, Recall: %5.2f, F1: %5.2f" % (
                    epoch, batch_loss.detach().cpu().item(),
                    acc_test, pr_test,
                    rc_test, f1_test
                )
            )
            print('=' * 100)

            with open(file_results, 'w') as f:
                value = {
                    "date": str(datetime.now()),
                    "num_epoch": 50,
                    "Accuracy": acc_test,
                    "Precision": pr_test,
                    "Recall": rc_test,
                    "F1": f1_test
                }
                json.dump(value, f)
                f.close()

        batch_loss.backward()
        optimizer.step()
    plt.plot(accuracy_score_train, label='train')
    plt.plot(accuracy_score_test, label='test')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Biểu đồ so sánh độ chính xác qua các epoch')
    plt.legend()
    plt.show()
