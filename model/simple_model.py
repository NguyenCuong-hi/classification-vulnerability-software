import torch
import torch.nn as nn


class SimpleModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, dropout_p=0.2, lambda1=0.5, lambda2=0.001, num_layers=4, *args):
        super(SimpleModel, self).__init__(*args)
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.dropout_p = dropout_p
        self.internal_dim = int(hidden_dim / 2)
        self.layer1 = nn.Sequential(
            nn.Linear(in_features=self.input_dim, out_features=self.hidden_dim, bias=True),
            nn.ReLU(),
            nn.Dropout(p=self.dropout_p)
        )
        self.feature = nn.ModuleList([nn.Sequential(
            nn.Linear(in_features=self.hidden_dim, out_features=self.internal_dim, bias=True),
            nn.ReLU(),
            nn.Dropout(p=self.dropout_p),
            nn.Linear(in_features=self.internal_dim, out_features=self.hidden_dim, bias=True),
            nn.ReLU(),
            nn.Dropout(p=self.dropout_p),
        ) for _ in range(num_layers)])

        self.classifier = nn.Sequential(
            nn.Linear(in_features=self.hidden_dim, out_features=2),
            nn.LogSoftmax(dim=-1)
        )

        self.lambda1 = lambda1
        self.lambda2 = lambda2
        self.loss_function = nn.NLLLoss(reduction='none')

    def forward(self, example_batch,
                targets=None,
                positive_batch=None,
                negative_batch=None):
        train_mode = (positive_batch is not None and
                      negative_batch is not None and
                      targets is not None)
        h_a = self.extract_feature(example_batch)
        y_a = self.classifier(h_a)
        probs = torch.exp(y_a)
        batch_loss = None
        if targets is not None:
            ce_loss = self.loss_function(input=y_a, target=targets)
            batch_loss = ce_loss.sum(dim=-1)
        if train_mode:
            h_p = self.extract_feature(positive_batch)
            h_n = self.extract_feature(negative_batch)
            dot_p = h_a.unsqueeze(dim=1) \
                .bmm(h_p.unsqueeze(dim=-1)).squeeze(-1).squeeze(-1)
            dot_n = h_a.unsqueeze(dim=1) \
                .bmm(h_n.unsqueeze(dim=-1)).squeeze(-1).squeeze(-1)
            mag_a = torch.norm(h_a, dim=-1)
            mag_p = torch.norm(h_p, dim=-1)
            mag_n = torch.norm(h_n, dim=-1)
            D_plus = 1 - (dot_p / (mag_a * mag_p))
            D_minus = 1 - (dot_n / (mag_a * mag_n))
            trip_loss = self.lambda1 * torch.abs((D_plus - D_minus + self.alpha))
            ce_loss = self.loss_function(input=y_a, target=targets)
            l2_loss = self.lambda2 * (mag_a + mag_p + mag_n)
            total_loss = ce_loss + trip_loss + l2_loss
            batch_loss = (total_loss).sum(dim=-1)
        return probs, h_a, batch_loss
        pass

    def extract_feature(self, x):
        out = self.layer1(x)

        for layer in self.feature:
            out = layer(out)
        return out
