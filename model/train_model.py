import copy
import json
from datetime import datetime

import numpy as np
import torch
from matplotlib import pyplot as plt
from sklearn.metrics import accuracy_score as acc, precision_score as pr, recall_score as rc, f1_score as f1
from tqdm import tqdm


def train(model, feature, target, dataset, num_epochs, file_data, valid_every=1, max_counter=20):
    print(" Starting training: ")
    train_loss = []
    batch_losses = []
    accuracy_score_train = []
    accuracy_score_test = []
    best_f1 = 0
    best_model = None
    patience_counter = 0
    for e in tqdm(range(num_epochs)):
        print("Epoch " + str(e) + "\n")
        num_batch = dataset.initialize_train_batches()

        # output_batches_generator = range(num_batch)
        # output_batches_generator = tqdm(output_batches_generator)
        # for batch in output_batches_generator:
        model.train()
        model.zero_grad()
        probabilities, representation, batch_loss = model(
            feature,
            targets=target
        )
        batch_losses.append(batch_loss.sum().detach().cpu().item())
        batch_loss.sum().backward()
        epoch_loss = np.sum(batch_losses).item()
        train_loss.append(epoch_loss)

        print('Train loss: %6.3f' % epoch_loss)
        print('=' * 100)
        train_acc, train_pr, train_rc, train_f1 = evaluate(
            model, dataset.create_tensor_train, num_batch)
        accuracy_score_train.append(train_acc)
        if e % valid_every == 0:
            valid_batch = dataset.initialize_valid_batches()
            valid_acc, valid_pr, valid_rc, valid_f1 = evaluate(
                model, dataset.create_tensor_valid, valid_batch)

            print('Valid Set: Acc: %6.3f\tPr: %6.3f\tRc %6.3f\tF1: %6.3f' % (valid_acc, valid_pr, valid_rc, valid_f1))
            print('=' * 100)

            if valid_f1 > best_f1:
                best_f1 = valid_f1
                patience_counter = 0
                best_model = copy.deepcopy(model.state_dict())
            else:
                patience_counter += 1
            if dataset.initialize_test_batches() != 0:
                test_batches = dataset.initialize_test_batches()
                test_acc, test_pr, test_rc, test_f1 = evaluate(
                    model, dataset.create_tensor_test, test_batches)
                print(
                    'Test Set: Acc: %6.3f\tPr: %6.3f\tRc %6.3f\tF1: %6.3f' % (test_acc, test_pr, test_rc, test_f1))
                print('=' * 100)
                accuracy_score_test.append(test_acc)
            if patience_counter == max_counter:
                if best_model is not None:
                    model.load_state_dict(best_model)
                break

    plt.plot(accuracy_score_train, label='train')
    plt.plot(accuracy_score_test, label='test')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Biểu đồ so sánh độ chính xác qua các epoch')
    plt.legend()
    plt.show()
    # plt.savefig(file_data + 'accuracy_chart.png')
    if dataset.initialize_test_batches() != 0:
        test_batches = dataset.initialize_test_batches()
        test_acc, test_pr, test_rc, test_f1 = evaluate(
            model, dataset.create_tensor_test, test_batches)
        print(
            'Test Set: Acc: %6.3f\tPr: %6.3f\tRc %6.3f\tF1: %6.3f' % (test_acc, test_pr, test_rc, test_f1))
        print('=' * 100)

        with open(file_data, 'w') as f:
            value = {
                "date": str(datetime.now()),
                "num_epoch": num_epochs,
                "Accuracy": test_acc,
                "Precision": test_pr,
                "Recall": test_rc,
                "F1": test_f1
            }
            json.dump(value, f)
            f.close()


def evaluate(model, iterator_function, _batch_count):
    model.eval()
    with torch.no_grad():
        predictions = []
        expectations = []
        batch_generator = range(_batch_count)

        for _ in batch_generator:
            features, targets = iterator_function()
            probs, _, _ = model(example_batch=features)
            batch_pred = np.argmax(probs.detach().cpu().numpy(), axis=-1).tolist()
            batch_tgt = targets.detach().cpu().numpy().tolist()
            predictions.extend(batch_pred)
            expectations.extend(batch_tgt)
        model.train()
        return acc(expectations, predictions) * 100, \
               pr(expectations, predictions) * 100, \
               rc(expectations, predictions) * 100, \
               f1(expectations, predictions) * 100,
